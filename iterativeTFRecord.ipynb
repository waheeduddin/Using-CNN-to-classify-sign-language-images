{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.range(100).map(\n",
    "    lambda x: x + tf.random_uniform([], -10, 10, tf.int64))\n",
    "validation_dataset = tf.data.Dataset.range(50)\n",
    "\n",
    "# Build an iterator that can take different datasets with the same type and shape\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# Get 2 init op for 2 different dataset\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(validation_init_op)\n",
    "    for _ in range(20):\n",
    "        #sess.run(training_init_op)\n",
    "        #for _ in range(100):\n",
    "        #    sess.run(next_element)\n",
    "\n",
    "        sess.run(validation_init_op)   #very cool\n",
    "        for _ in range(50):\n",
    "            sess.run(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#import os\n",
    "\n",
    "#data_path = 'C:/Users/Gebruiker/PycharmProjects/TFRecords/train.tfrecords'\n",
    "data_path = './extra.tfrecords'\n",
    "def parser(serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    feature_myTFrecord = {'train/image': tf.FixedLenFeature([], tf.string), #you wrote the files even in the validate set as train BAKAYARO\n",
    "               'train/label': tf.FixedLenFeature([], tf.int64)}\n",
    "    \n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,features= feature_myTFrecord)\n",
    "    \n",
    "    \n",
    "    image = tf.decode_raw(features['train/image'], tf.float32)\n",
    "\n",
    "    # Cast label data into int32\n",
    "    temp_label = tf.cast(features['train/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, [575, 400, 1])\n",
    "\n",
    "    label = tf.cast(tf.subtract(temp_label, 1), tf.int32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "#filenames = [os.path.join(\".\", 'f1.tfrecords'), os.path.join(\".\", 'f2.tfrecords')]\n",
    "filenames = data_path\n",
    "batch_size =3 \n",
    "NUM_PER_EPOCH = 30\n",
    "# Repeat infinitely.\n",
    "dataset = tf.data.TFRecordDataset(filenames,buffer_size=2 * batch_size,num_parallel_reads=4)#.repeat()\n",
    "\n",
    "# Parse records.\n",
    "dataset = dataset.map(parser)\n",
    "\n",
    "# Potentially shuffle records.\n",
    "min_queue_examples = int(NUM_PER_EPOCH * 0.4)\n",
    "dataset = dataset.shuffle(buffer_size=min_queue_examples + 3 * batch_size)\n",
    "# Batch it up.\n",
    "dataset = dataset.batch(batch_size)\n",
    "    #iterator = dataset.make_one_shot_iterator()\n",
    "    #image_batch, label_batch = iterator.get_next()\n",
    "iterator = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)\n",
    "next_element = iterator.get_next()    \n",
    "\n",
    "training_init_op = iterator.make_initializer(dataset)\n",
    "\n",
    "#return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.run(training_init_op)\n",
    "        #for _ in range(100):\n",
    "        #    sess.run(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  epoch and iteration  0\n",
      "0  epoch and iteration  1\n",
      "0  epoch and iteration  2\n",
      "0  epoch and iteration  3\n",
      "0  epoch and iteration  4\n",
      "0  epoch and iteration  5\n",
      "0  epoch and iteration  6\n",
      "0  epoch and iteration  7\n",
      "0  epoch and iteration  8\n",
      "0  epoch and iteration  9\n",
      "1  epoch and iteration  0\n",
      "1  epoch and iteration  1\n",
      "1  epoch and iteration  2\n",
      "1  epoch and iteration  3\n",
      "1  epoch and iteration  4\n",
      "1  epoch and iteration  5\n",
      "1  epoch and iteration  6\n",
      "1  epoch and iteration  7\n",
      "1  epoch and iteration  8\n",
      "1  epoch and iteration  9\n",
      "2  epoch and iteration  0\n",
      "2  epoch and iteration  1\n",
      "2  epoch and iteration  2\n",
      "2  epoch and iteration  3\n",
      "2  epoch and iteration  4\n",
      "2  epoch and iteration  5\n",
      "2  epoch and iteration  6\n",
      "2  epoch and iteration  7\n",
      "2  epoch and iteration  8\n",
      "2  epoch and iteration  9\n",
      "3  epoch and iteration  0\n",
      "error has occured!!!  0\n",
      "4  epoch and iteration  0\n",
      "4  epoch and iteration  1\n",
      "4  epoch and iteration  2\n",
      "4  epoch and iteration  3\n",
      "4  epoch and iteration  4\n",
      "4  epoch and iteration  5\n",
      "4  epoch and iteration  6\n",
      "4  epoch and iteration  7\n",
      "4  epoch and iteration  8\n",
      "4  epoch and iteration  9\n",
      "5  epoch and iteration  0\n",
      "5  epoch and iteration  1\n",
      "5  epoch and iteration  2\n",
      "5  epoch and iteration  3\n",
      "5  epoch and iteration  4\n",
      "5  epoch and iteration  5\n",
      "5  epoch and iteration  6\n",
      "5  epoch and iteration  7\n",
      "5  epoch and iteration  8\n",
      "5  epoch and iteration  9\n",
      "6  epoch and iteration  0\n",
      "6  epoch and iteration  1\n",
      "6  epoch and iteration  2\n",
      "6  epoch and iteration  3\n",
      "6  epoch and iteration  4\n",
      "6  epoch and iteration  5\n",
      "6  epoch and iteration  6\n",
      "6  epoch and iteration  7\n",
      "6  epoch and iteration  8\n",
      "6  epoch and iteration  9\n",
      "7  epoch and iteration  0\n",
      "error has occured!!!  0\n",
      "8  epoch and iteration  0\n",
      "8  epoch and iteration  1\n",
      "8  epoch and iteration  2\n",
      "8  epoch and iteration  3\n",
      "8  epoch and iteration  4\n",
      "8  epoch and iteration  5\n",
      "8  epoch and iteration  6\n",
      "8  epoch and iteration  7\n",
      "8  epoch and iteration  8\n",
      "8  epoch and iteration  9\n",
      "9  epoch and iteration  0\n",
      "9  epoch and iteration  1\n",
      "9  epoch and iteration  2\n",
      "9  epoch and iteration  3\n",
      "9  epoch and iteration  4\n",
      "9  epoch and iteration  5\n",
      "9  epoch and iteration  6\n",
      "9  epoch and iteration  7\n",
      "9  epoch and iteration  8\n",
      "9  epoch and iteration  9\n",
      "10  epoch and iteration  0\n",
      "10  epoch and iteration  1\n",
      "10  epoch and iteration  2\n",
      "10  epoch and iteration  3\n",
      "10  epoch and iteration  4\n",
      "10  epoch and iteration  5\n",
      "10  epoch and iteration  6\n",
      "10  epoch and iteration  7\n",
      "10  epoch and iteration  8\n",
      "10  epoch and iteration  9\n",
      "11  epoch and iteration  0\n",
      "error has occured!!!  0\n",
      "12  epoch and iteration  0\n",
      "12  epoch and iteration  1\n",
      "12  epoch and iteration  2\n",
      "12  epoch and iteration  3\n",
      "12  epoch and iteration  4\n",
      "12  epoch and iteration  5\n",
      "12  epoch and iteration  6\n",
      "12  epoch and iteration  7\n",
      "12  epoch and iteration  8\n",
      "12  epoch and iteration  9\n",
      "13  epoch and iteration  0\n",
      "13  epoch and iteration  1\n",
      "13  epoch and iteration  2\n",
      "13  epoch and iteration  3\n",
      "13  epoch and iteration  4\n",
      "13  epoch and iteration  5\n",
      "13  epoch and iteration  6\n",
      "13  epoch and iteration  7\n",
      "13  epoch and iteration  8\n",
      "13  epoch and iteration  9\n",
      "14  epoch and iteration  0\n",
      "14  epoch and iteration  1\n",
      "14  epoch and iteration  2\n",
      "14  epoch and iteration  3\n",
      "14  epoch and iteration  4\n",
      "14  epoch and iteration  5\n",
      "14  epoch and iteration  6\n",
      "14  epoch and iteration  7\n",
      "14  epoch and iteration  8\n",
      "14  epoch and iteration  9\n",
      "15  epoch and iteration  0\n",
      "error has occured!!!  0\n",
      "16  epoch and iteration  0\n",
      "16  epoch and iteration  1\n",
      "16  epoch and iteration  2\n",
      "16  epoch and iteration  3\n",
      "16  epoch and iteration  4\n",
      "16  epoch and iteration  5\n",
      "16  epoch and iteration  6\n",
      "16  epoch and iteration  7\n",
      "16  epoch and iteration  8\n",
      "16  epoch and iteration  9\n",
      "17  epoch and iteration  0\n",
      "17  epoch and iteration  1\n",
      "17  epoch and iteration  2\n",
      "17  epoch and iteration  3\n",
      "17  epoch and iteration  4\n",
      "17  epoch and iteration  5\n",
      "17  epoch and iteration  6\n",
      "17  epoch and iteration  7\n",
      "17  epoch and iteration  8\n",
      "17  epoch and iteration  9\n",
      "18  epoch and iteration  0\n",
      "18  epoch and iteration  1\n",
      "18  epoch and iteration  2\n",
      "18  epoch and iteration  3\n",
      "18  epoch and iteration  4\n",
      "18  epoch and iteration  5\n",
      "18  epoch and iteration  6\n",
      "18  epoch and iteration  7\n",
      "18  epoch and iteration  8\n",
      "18  epoch and iteration  9\n",
      "19  epoch and iteration  0\n",
      "error has occured!!!  0\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "counts = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(training_init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess,coord=coord)\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(10):\n",
    "            print(epoch,' epoch and iteration ' , iteration)\n",
    "            try:\n",
    "                X_batch, y_batch = sess.run(next_element)\n",
    "                counts = counts + 1\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print('error has occured!!! ' , iteration)\n",
    "                sess.run(training_init_op)\n",
    "                break\n",
    "            \n",
    "    coord.request_stop()\n",
    "\n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './extra.tfrecords'\n",
    "def parser(serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    feature_myTFrecord = {'train/image': tf.FixedLenFeature([], tf.string), #you wrote the files even in the validate set as train BAKAYARO\n",
    "               'train/label': tf.FixedLenFeature([], tf.int64)}\n",
    "    \n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,features= feature_myTFrecord)\n",
    "    \n",
    "    \n",
    "    image = tf.decode_raw(features['train/image'], tf.float32)\n",
    "\n",
    "    # Cast label data into int32\n",
    "    temp_label = tf.cast(features['train/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, [575, 400, 1])\n",
    "\n",
    "    label = tf.cast(tf.subtract(temp_label, 1), tf.int32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "#filenames = [os.path.join(\".\", 'f1.tfrecords'), os.path.join(\".\", 'f2.tfrecords')]\n",
    "filenames = data_path\n",
    "batch_size =3 \n",
    "NUM_PER_EPOCH = 30\n",
    "# Repeat infinitely.\n",
    "dataset = tf.data.TFRecordDataset(filenames,buffer_size=2 * batch_size,num_parallel_reads=4)#.repeat()\n",
    "\n",
    "# Parse records.\n",
    "dataset = dataset.map(parser)\n",
    "\n",
    "# Potentially shuffle records.\n",
    "min_queue_examples = int(NUM_PER_EPOCH * 0.4)\n",
    "dataset = dataset.shuffle(buffer_size=min_queue_examples + 3 * batch_size)\n",
    "# Batch it up.\n",
    "dataset = dataset.batch(batch_size)\n",
    "    #iterator = dataset.make_one_shot_iterator()\n",
    "    #image_batch, label_batch = iterator.get_next()\n",
    "iterator = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)\n",
    "next_element = iterator.get_next()    \n",
    "\n",
    "training_init_op = iterator.make_initializer(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 575\n",
    "width = 400\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "\n",
    "conv1_fmaps = 96\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 128\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "n_fc1 = 64\n",
    "n_outputs = 36\n",
    "\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, height,width,channels], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None],name = 'y')\n",
    "\n",
    "    ####to get the labels start from 0\n",
    "    \n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 144 * 100])\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  epoch and iteration  0\n",
      "0  epoch and iteration  1\n",
      "0  epoch and iteration  2\n",
      "0  epoch and iteration  3\n",
      "0  epoch and iteration  4\n",
      "0  epoch and iteration  5\n",
      "0  epoch and iteration  6\n",
      "0  epoch and iteration  7\n",
      "0  epoch and iteration  8\n",
      "0  epoch and iteration  9\n",
      "0 Train accuracy: 0.33333334\n",
      "1  epoch and iteration  0\n",
      "1  epoch and iteration  1\n",
      "1  epoch and iteration  2\n",
      "1  epoch and iteration  3\n",
      "1  epoch and iteration  4\n",
      "1  epoch and iteration  5\n",
      "1  epoch and iteration  6\n",
      "1  epoch and iteration  7\n",
      "1  epoch and iteration  8\n",
      "1  epoch and iteration  9\n",
      "1 Train accuracy: 1.0\n",
      "2  epoch and iteration  0\n",
      "2  epoch and iteration  1\n",
      "2  epoch and iteration  2\n",
      "2  epoch and iteration  3\n",
      "2  epoch and iteration  4\n",
      "2  epoch and iteration  5\n",
      "2  epoch and iteration  6\n",
      "2  epoch and iteration  7\n",
      "2  epoch and iteration  8\n",
      "2  epoch and iteration  9\n",
      "2 Train accuracy: 1.0\n",
      "3  epoch and iteration  0\n",
      "error has occured!!!  0\n",
      "3 Train accuracy: 1.0\n",
      "4  epoch and iteration  0\n",
      "4  epoch and iteration  1\n",
      "4  epoch and iteration  2\n",
      "4  epoch and iteration  3\n",
      "4  epoch and iteration  4\n",
      "4  epoch and iteration  5\n",
      "4  epoch and iteration  6\n",
      "4  epoch and iteration  7\n",
      "4  epoch and iteration  8\n",
      "4  epoch and iteration  9\n",
      "4 Train accuracy: 1.0\n",
      "5  epoch and iteration  0\n",
      "5  epoch and iteration  1\n",
      "5  epoch and iteration  2\n",
      "5  epoch and iteration  3\n",
      "5  epoch and iteration  4\n",
      "5  epoch and iteration  5\n",
      "5  epoch and iteration  6\n",
      "5  epoch and iteration  7\n",
      "5  epoch and iteration  8\n",
      "5  epoch and iteration  9\n",
      "5 Train accuracy: 1.0\n",
      "6  epoch and iteration  0\n",
      "6  epoch and iteration  1\n",
      "6  epoch and iteration  2\n",
      "6  epoch and iteration  3\n",
      "6  epoch and iteration  4\n",
      "6  epoch and iteration  5\n",
      "6  epoch and iteration  6\n",
      "6  epoch and iteration  7\n",
      "6  epoch and iteration  8\n",
      "6  epoch and iteration  9\n",
      "6 Train accuracy: 1.0\n",
      "7  epoch and iteration  0\n",
      "error has occured!!!  0\n",
      "7 Train accuracy: 1.0\n",
      "8  epoch and iteration  0\n",
      "8  epoch and iteration  1\n",
      "8  epoch and iteration  2\n",
      "8  epoch and iteration  3\n",
      "8  epoch and iteration  4\n",
      "8  epoch and iteration  5\n",
      "8  epoch and iteration  6\n",
      "8  epoch and iteration  7\n",
      "8  epoch and iteration  8\n",
      "8  epoch and iteration  9\n",
      "8 Train accuracy: 0.6666667\n",
      "9  epoch and iteration  0\n",
      "9  epoch and iteration  1\n",
      "9  epoch and iteration  2\n",
      "9  epoch and iteration  3\n",
      "9  epoch and iteration  4\n",
      "9  epoch and iteration  5\n",
      "9  epoch and iteration  6\n",
      "9  epoch and iteration  7\n",
      "9  epoch and iteration  8\n",
      "9  epoch and iteration  9\n",
      "9 Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs = 10\n",
    "#n_epochs = 5\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess,coord=coord)\n",
    "    sess.run(training_init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess,coord=coord)\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(10):\n",
    "            print(epoch,' epoch and iteration ' , iteration)\n",
    "            try:\n",
    "                X_batch, y_batch = sess.run(next_element)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print('error has occured!!! ' , iteration)\n",
    "                sess.run(training_init_op)\n",
    "                X_batch, y_batch = sess.run(next_element)\n",
    "                break\n",
    "            sess.run([training_op], feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        print(epoch, \"Train accuracy:\", acc_train)\n",
    "    \n",
    "    coord.request_stop()\n",
    "\n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
